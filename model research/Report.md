# Отчет
## _Модели_
В качестве инструмента, для извлечения признаково описания из текста, были выбраны модели [distilbert-base-cased](https://huggingface.co/distilbert/distilbert-base-cased) и [roberta-base](https://huggingface.co/FacebookAI/roberta-base). Так же подобраны две архитектуры классификатора. 
1-я архитектура.
- выходы со всех токенов переходят в слой drop out.
- результат переходит в полносвязанный слой.
- числа на выходе превращаем в вероятности с помощью функции softmax.

2-я архитектура.
- для токенов предложения проделываем mean и max pooling.
- конкатинация пуллингов.
- полносвязанный слой с переходом на 1024 нейрона.
- функция активации(ReLU).
- полносвязанный слой.
- числа на выходе превращаем в вероятности с помощью функции softmax.

## _Данные_
Для анализа задачи был выбран [датасет](https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently) с похожей задачей классификации на несколько классов. Датасет имеет размер в 837 ненулевых записей и разделён на 4 класса.

## _Результаты обучения_
По результатам обучения можно сделать вывод, что все модели достигли примерно одинаковых результатов на валидационной выборке. По поведению обучения 2-ой архитектуры можно понять, что для обучения на большем наборе данных потребуется меньшая скорость обучения.
